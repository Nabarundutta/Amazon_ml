{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5303ca2-7656-4931-a57d-50dd15ddc55e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3108b2d4-bab6-4640-8b52-f5602019e74b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name   \n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight  \\\n",
       "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
       "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
       "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
       "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
       "\n",
       "     entity_value  \n",
       "0      500.0 gram  \n",
       "1         1.0 cup  \n",
       "2      0.709 gram  \n",
       "3      0.709 gram  \n",
       "4  1400 milligram  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bce3a11-52eb-4065-aebe-5d33647c6d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://m.media-amazon.com/images/I/612mrlqiI4L.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['image_link'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01fca11d-2fac-4ccf-9a70-280764aef092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import download_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a842297e-0cc7-4056-84a3-7b1e647a6c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_name_ex(txt):\n",
    "       return txt.split(\"/\")[-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43fa405-db5b-482a-9851-b47b5739dff8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (260272309.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def my_funtion(img_link):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71423c28-13db-4309-952d-5cbd2d657a04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'612mrlqiI4L.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name_ex('https://m.media-amazon.com/images/I/612mrlqiI4L.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bf0525-c4b7-4c7b-9bf7-3650bc6d9639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"image_name\"] = df['image_link'].apply(image_name_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc6d95d-711c-4da2-897e-375b3dd20d50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>61I9XdN6OFL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "      <td>71gSRbyXmoL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>61BZ4zrjZXL.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>612mrlqiI4L.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "      <td>617Tl40LOXL.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name   \n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight  \\\n",
       "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
       "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
       "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
       "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
       "\n",
       "     entity_value       image_name  \n",
       "0      500.0 gram  61I9XdN6OFL.jpg  \n",
       "1         1.0 cup  71gSRbyXmoL.jpg  \n",
       "2      0.709 gram  61BZ4zrjZXL.jpg  \n",
       "3      0.709 gram  612mrlqiI4L.jpg  \n",
       "4  1400 milligram  617Tl40LOXL.jpg  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "946c423a-c6bd-4093-8615-7203db62ee62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5069d2d-d225-461a-aeee-38b2007781a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base = 'Downloads/student_resource 3/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b45d5bcd-7b48-434b-818a-9c8b291807b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_loader(image_name,image_base=image_base):\n",
    "\n",
    "    image_path = os.path.join(image_base,image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b56e4626-a930-4d54-b5dc-98bb7a428133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Downloads/student_resource 3/images/61I9XdN6OFL.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_loader('61I9XdN6OFL.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38ab36c6-95cc-44c0-b017-e56bfea4c8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.8.1.78)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opencv-python) (1.24.3)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.8.1.78\n",
      "    Uninstalling opencv-python-4.8.1.78:\n",
      "      Successfully uninstalled opencv-python-4.8.1.78\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0de9c9f8-7764-4705-b6ec-5bfbcd8ea9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9443e5ae-3803-4e0d-b459-011fb241182d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_numbers(image_path):\n",
    "    \n",
    "\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)   \n",
    "\n",
    "\n",
    "\n",
    "    numbers = image.flatten()\n",
    "    \n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "536d2f8e-9233-4620-a03b-438d9cd8d9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@331.273] global loadsave.cpp:241 findDecoder imread_('Downloads/student_resource 3/images/61I9XdN6OFL.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimage_to_numbers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDownloads/student_resource 3/images/61I9XdN6OFL.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m, in \u001b[0;36mimage_to_numbers\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimage_to_numbers\u001b[39m(image_path):\n\u001b[1;32m      5\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m----> 8\u001b[0m     gray_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m     12\u001b[0m     numbers \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numbers\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "image_to_numbers('Downloads/student_resource 3/images/61I9XdN6OFL.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f61c244d-2958-4e77-b221-e2c472a828aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_to_numbers(image_path):\n",
    "    \"\"\"Converts an image to a numerical representation.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Numerical representation of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image using PIL\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = image.convert(\"L\")\n",
    "\n",
    "    # Get the image dimensions\n",
    "    width, height = gray_image.size\n",
    "\n",
    "    # Convert the image to a numerical array\n",
    "    numbers = []\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            pixel_value = gray_image.getpixel((x, y))\n",
    "            numbers.append(pixel_value)\n",
    "\n",
    "    return numbers\n",
    "\n",
    "# Example usage\n",
    "image_path = '../images/61I9XdN6OFL.jpg'  # Replace with the actual path to your image\n",
    "numbers = image_to_numbers(image_path)\n",
    "\n",
    "print(numbers)  # Print the numerical representation of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c5e08-2bc9-4463-9b62-13412f96559c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
